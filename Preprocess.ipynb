{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abuwildanm/food-recognition/blob/master/Create_Custom_Dataset_From_Google_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18KDj58LuNAM"
      },
      "source": [
        "## Rename images & categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Nd57acPWx1pS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# use this to rename the categories of the folder generated by the chrome extension\n",
        "list_categories = os.listdir('./dataset_no_split')\n",
        "list_categories_new = [category.replace('foto makanan ', '').replace(' - Google Penelusuran', '').replace(' ', '-') for category in list_categories]\n",
        "map_categories = dict(zip(list_categories, list_categories_new))\n",
        "# Rename categories\n",
        "for before, after in map_categories.items():\n",
        "     os.rename('./dataset_no_split/{}'.format(before), './dataset_no_split/{}'.format(after))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko0ZT7ZD3Y6a",
        "outputId": "646b9b69-723b-4694-ff62-2317dd77d9d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images\n",
            ".gitkeep: 0\n",
            "perkedel-kentang: 476\n",
            "tahu-gejrot: 399\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "\n",
        "print('Number of images')\n",
        "# before processing the images, locate the dataset folder for each category to dataset_no_split folder, such as dataset_no_split/mie_aceh\n",
        "categories = os.listdir('./dataset_no_split')\n",
        "for cat in categories:\n",
        "    print('{}: {}'.format(cat, len(glob('dataset_no_split/{}/*'.format(cat)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IExOCCDcY-5t"
      },
      "outputs": [],
      "source": [
        "# Remove invalid images\n",
        "all_image = glob('dataset_no_split/*/*')\n",
        "for img_path in all_image:\n",
        "    if os.path.getsize(img_path) == 0 and os.path.exists(img_path):\n",
        "        os.remove(img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn28Vg0oarNc",
        "outputId": "cfd63962-5cff-41c5-924a-6fc0d18ceff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of valid images\n",
            ".gitkeep: 0\n",
            "perkedel-kentang: 476\n",
            "tahu-gejrot: 399\n"
          ]
        }
      ],
      "source": [
        "print('Number of valid images')\n",
        "categories = os.listdir('./dataset_no_split')\n",
        "for cat in categories:\n",
        "    print('{}: {}'.format(cat, len(glob('dataset_no_split/{}/*'.format(cat)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "crtFecvoO2pW"
      },
      "outputs": [],
      "source": [
        "# Rename each image from each category (ex: mie_aceh-1.jpg, mie_aceh-2.jpg, etc for category mie_aceh)\n",
        "for cat in categories:\n",
        "    for i, path in enumerate(sorted(glob('dataset_no_split/{}/*'.format(cat))), 1):\n",
        "        dirname = os.path.dirname(path)\n",
        "        src = path\n",
        "        dst = os.path.join(dirname, '{}-{}.jpg'.format(cat, i))\n",
        "        # Rename images\n",
        "        os.rename(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfm4zLO1vVmg"
      },
      "source": [
        "## Resize Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remove dataset_no_split\\tahu-gejrot\\tahu-gejrot-83.jpg\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# The path of all image in dataset\n",
        "image_path = glob('dataset_no_split/*/*') # change with desired path because some of the dataset already resized\n",
        "# Resize process\n",
        "image_size = (224, 224)\n",
        "for path in image_path:\n",
        "    try:\n",
        "        # Load the image from path\n",
        "        image = tf.keras.preprocessing.image.load_img(path)\n",
        "        # Resize the image\n",
        "        image = image.resize(image_size)\n",
        "        # Save the resized image\n",
        "        image.save(path)\n",
        "    except:\n",
        "        # Remove the image if it is not valid\n",
        "        print('Remove {}'.format(path))\n",
        "        os.remove(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rqDuADWcXVD"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cfTqzqR6YFoK"
      },
      "outputs": [],
      "source": [
        "# Make train and test directory\n",
        "os.makedirs('dataset/train', exist_ok=True)\n",
        "os.makedirs('dataset/test', exist_ok=True)\n",
        "\n",
        "# Make category directory in train and test\n",
        "for cat in categories:\n",
        "    os.makedirs('dataset/train/{}'.format(cat), exist_ok=True)\n",
        "    os.makedirs('dataset/test/{}'.format(cat), exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nV2cHnd1gbaE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "# Pick 20 percent of each category images as test set\n",
        "for cat in categories:\n",
        "    test_size = int(len(glob('dataset_no_split/{}/*'.format(cat))) * 0.2)\n",
        "    all_cat_image = glob('dataset_no_split/{}/*'.format(cat))\n",
        "    np.random.shuffle(all_cat_image)\n",
        "    for img_path in sorted(all_cat_image):\n",
        "        if len(os.listdir('dataset/test/{}'.format(cat))) <= test_size:\n",
        "            shutil.move(img_path, 'dataset/test/{}'.format(cat))\n",
        "        else:\n",
        "            shutil.move(img_path, 'dataset/train/{}'.format(cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijwmcVeyDJaJ",
        "outputId": "f712efdf-f34f-4507-b2a9-92dde6ad6d13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Images\n",
            ".gitkeep: 0\n",
            "bakso: 315\n",
            "bala-bala: 272\n",
            "batagor: 321\n",
            "bebek-betutu: 238\n",
            "bika-ambon: 320\n",
            "dadar-gulung: 151\n",
            "gado-gado: 263\n",
            "gehu: 209\n",
            "gudeg: 213\n",
            "gulai-ikan: 384\n",
            "kerak-telor: 192\n",
            "kolak: 369\n",
            "kue-cubit: 151\n",
            "mie-aceh: 285\n",
            "nasi-goreng: 366\n",
            "nasi-uduk: 344\n",
            "otak-otak: 315\n",
            "pempek: 286\n",
            "pepes-ikan: 148\n",
            "perkedel-kentang: 380\n",
            "pisang-goreng: 316\n",
            "putu-ayu: 151\n",
            "rawon: 235\n",
            "rendang: 237\n",
            "sate: 355\n",
            "semur-jengkol: 275\n",
            "soto: 358\n",
            "tahu-gejrot: 318\n",
            "telur-balado: 148\n",
            "tempe-bacem: 145\n",
            "tempe-goreng: 303\n",
            "====================\n",
            "Test Images\n",
            ".gitkeep: 0\n",
            "bakso: 130\n",
            "bala-bala: 69\n",
            "batagor: 81\n",
            "bebek-betutu: 97\n",
            "bika-ambon: 77\n",
            "dadar-gulung: 38\n",
            "gado-gado: 113\n",
            "gehu: 53\n",
            "gudeg: 82\n",
            "gulai-ikan: 97\n",
            "kerak-telor: 49\n",
            "kolak: 93\n",
            "kue-cubit: 38\n",
            "mie-aceh: 65\n",
            "nasi-goreng: 155\n",
            "nasi-uduk: 87\n",
            "otak-otak: 80\n",
            "pempek: 123\n",
            "pepes-ikan: 38\n",
            "perkedel-kentang: 96\n",
            "pisang-goreng: 79\n",
            "putu-ayu: 39\n",
            "rawon: 104\n",
            "rendang: 94\n",
            "sate: 154\n",
            "semur-jengkol: 69\n",
            "soto: 141\n",
            "tahu-gejrot: 80\n",
            "telur-balado: 38\n",
            "tempe-bacem: 37\n",
            "tempe-goreng: 77\n"
          ]
        }
      ],
      "source": [
        "categories_split = os.listdir('./dataset/train/')\n",
        "print('Train Images')\n",
        "for cat in categories_split:\n",
        "    print('{}: {}'.format(cat, len(glob('dataset/train/{}/*'.format(cat)))))\n",
        "\n",
        "print('='*20)\n",
        "print('Test Images')\n",
        "for cat in categories_split:\n",
        "    print('{}: {}'.format(cat, len(glob('dataset/test/{}/*'.format(cat)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VpU9OnYuROw9"
      },
      "outputs": [],
      "source": [
        "# Remove parent category directory\n",
        "for cat in categories:\n",
        "    shutil.rmtree('dataset_no_split/{}'.format(cat), ignore_errors=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNRo93MMopBLidqmcW13LF1",
      "include_colab_link": true,
      "name": "Create Custom Dataset From Google Images.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
