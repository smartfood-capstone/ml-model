{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (224, 224)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce GTX 1650, compute capability 7.5\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "precision = 'mixed_float16'\n",
    "policy = tf.keras.mixed_precision.Policy(precision)\n",
    "tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet_V2_50 = 'https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5'\n",
    "Inception_V3 = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\n",
    "MobileNet_V3_Large = 'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5'\n",
    "Inception_ResNet_V2 = 'https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/5'\n",
    "EfficientNet_B0 = 'https://tfhub.dev/google/efficientnet/b0/classification/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('val_accuracy') > 0.95):\n",
    "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "  initial_lr = 1e-3\n",
    "  new_lr = initial_lr * 0.9 ** epoch\n",
    "\n",
    "  return new_lr\n",
    "\n",
    "callbacks = myCallback()\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  image = tf.cast(image, tf.float32) / 255.0\n",
    "  return image\n",
    "\n",
    "def get_label(file_path, class_names):\n",
    "  parts = tf.strings.split(file_path, os.sep)\n",
    "  label = parts[-2] == class_names\n",
    "  return label\n",
    "\n",
    "def load_image_and_label(file_path, class_names):\n",
    "  label = get_label(file_path, class_names)\n",
    "  image = tf.io.read_file(file_path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  return image, label\n",
    "\n",
    "def prepare_dataset(directory, class_names, batch_size, training=True):\n",
    "  dataset = tf.data.Dataset.list_files(os.path.join(directory, '*/*'))\n",
    "  dataset = dataset.map(lambda x: load_image_and_label(x, class_names), num_parallel_calls=AUTOTUNE)\n",
    "  dataset = dataset.map(lambda x, y: (preprocess_image(x), y), num_parallel_calls=AUTOTUNE)\n",
    "  if training:\n",
    "    dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "  return dataset\n",
    "\n",
    "def create_dataset(train_dir, test_dir, batch_size=BATCH_SIZE):\n",
    "  class_names = tf.io.gfile.listdir(train_dir)\n",
    "  total_class = len(class_names)\n",
    "  class_names = tf.constant(class_names)\n",
    "\n",
    "  train_dataset = prepare_dataset(train_dir, class_names, batch_size, training=True)\n",
    "  test_dataset = prepare_dataset(test_dir, class_names, batch_size, training=False)\n",
    "\n",
    "  return train_dataset, test_dataset, total_class\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(pre_trained_model, total_class):\n",
    "  feature_extractor_layer = hub.KerasLayer(pre_trained_model, input_shape=(224, 224, 3), trainable=False, dtype=tf.float32)\n",
    "  model = tf.keras.Sequential([\n",
    "    feature_extractor_layer,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001), dtype=tf.float32),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001), dtype=tf.float32),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(total_class, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "def fit_model(model, train_generator, test_generator, epochs, callbacks = []):\n",
    "  history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=test_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    "  )\n",
    "\n",
    "  return history\n",
    "\n",
    "def save_model(model, pre_trained_model, type):\n",
    "  model.save('model_MobileNet_Makanan_{}.h5'.format(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_metric(model_history, metric_name, epochs = 10):\n",
    "  metric = model_history.history[metric_name]\n",
    "  avg_metric = np.mean(metric[-epochs:])\n",
    "  return avg_metric\n",
    "\n",
    "def predict(model, test_dataset: tf.data.Dataset, total_class):\n",
    "  wrong_images = []\n",
    "  wrong_labels = []\n",
    "  wrong_predictions = []\n",
    "  wrong_actual = np.zeros(total_class)\n",
    "  total_class_data = np.zeros(total_class)\n",
    "  test_dataset = test_dataset.shuffle(buffer_size=1000)\n",
    "  test_dataset = test_dataset.take(int(len(test_dataset) * 0.6))\n",
    "  for images, labels in test_dataset:\n",
    "    predictions = model.predict(images)\n",
    "    for i in range(len(predictions)):\n",
    "      if np.argmax(predictions[i]) != np.argmax(labels[i]):\n",
    "        wrong_predictions.append(predictions[i])\n",
    "        wrong_images.append(images[i])\n",
    "        wrong_labels.append(labels[i])\n",
    "        wrong_actual[np.argmax(labels[i])] += 1\n",
    "      total_class_data[np.argmax(labels[i])] += 1\n",
    "\n",
    "def show_missclassified_images(wrong_images, wrong_labels, wrong_predictions, class_names, test_generator):\n",
    "  total_row = int(np.ceil(len(wrong_predictions) / 5))\n",
    "  fig = plt.figure(figsize=(20, total_row * 5))\n",
    "  for i in range(total_row):\n",
    "    remainder = len(wrong_predictions) - i * 5\n",
    "    total = remainder if remainder < 5 else 5\n",
    "    for j in range(total):\n",
    "      idx = i * 5 + j\n",
    "      ax = fig.add_subplot(total_row, 5, idx + 1)\n",
    "      ax.imshow(wrong_images[idx])\n",
    "      ax.set_title('Prediction: ' + class_names[np.argmax(wrong_predictions[idx])] + ' ' + str(round(np.sort(wrong_predictions[idx])[-1] * 100, 2)) +\n",
    "                  '\\nPrediction2: ' + class_names[np.argsort(wrong_predictions[idx])[-2]] + ' ' + str(round(np.sort(wrong_predictions[idx])[-2] * 100, 2)) +\n",
    "                    '\\nPrediction3: ' + class_names[np.argsort(wrong_predictions[idx])[-3]] + ' ' + str(round(np.sort(wrong_predictions[idx])[-3] * 100, 2)) +\n",
    "                  '\\nActual: ' + class_names[np.argmax(wrong_labels[idx])] + \n",
    "                  '\\nFilename: ' + test_generator.filenames[idx])\n",
    "      ax.axis('off')\n",
    "\n",
    "def plot_graphs(model_history, metric):\n",
    "  plt.plot(model_history.history[metric])\n",
    "  plt.plot(model_history.history['val_'+metric])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric], loc='upper right')\n",
    "  plt.title('Model ' + metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Jajanan Pasar Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = MobileNet_V3_Large\n",
    "train_path = './dataset/jajanan/train/'\n",
    "test_path = './dataset/jajanan/test/'\n",
    "\n",
    "train_gen, test_gen, total_class = create_dataset(train_path, test_path)\n",
    "\n",
    "model = create_model(pre_trained_model, total_class)\n",
    "model_history = fit_model(model, train_gen, test_gen, 50, [callbacks, lr_scheduler, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(train_path)\n",
    "\n",
    "wrong_pred, wrong_images, wrong_labels, wrong_actual_percentage, total_class_data = predict(model, test_gen, total_class)\n",
    "print('Accuracy: ', (test_gen.n - len(wrong_pred)) / test_gen.n * 100, '%')\n",
    "print('Wrong Prediction: ')\n",
    "for i in range(total_class):\n",
    "  print(class_names[i], ': ', wrong_actual_percentage[i], '/', total_class_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missclassified_images(wrong_images, wrong_labels, wrong_pred, class_names, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(model, 'accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(model, 'loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Makanan Tradisional Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = EfficientNet_B0\n",
    "train_path = './dataset/makanan/train/'\n",
    "test_path = './dataset/makanan/test/'\n",
    "\n",
    "train_gen, test_gen, total_class = create_dataset(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_5 (KerasLayer)  (None, 1000)              5330564   \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              1025024   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 31)                15903     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,896,291\n",
      "Trainable params: 1,565,727\n",
      "Non-trainable params: 5,330,564\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "195/195 [==============================] - 50s 230ms/step - loss: 3.4681 - accuracy: 0.4502 - val_loss: 2.3144 - val_accuracy: 0.7162 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 42s 210ms/step - loss: 2.3670 - accuracy: 0.6626 - val_loss: 1.9172 - val_accuracy: 0.7745 - lr: 9.0000e-04\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 43s 218ms/step - loss: 1.9690 - accuracy: 0.7250 - val_loss: 1.6943 - val_accuracy: 0.7903 - lr: 8.1000e-04\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 42s 213ms/step - loss: 1.7302 - accuracy: 0.7621 - val_loss: 1.5295 - val_accuracy: 0.8090 - lr: 7.2900e-04\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 42s 213ms/step - loss: 1.5436 - accuracy: 0.7934 - val_loss: 1.4010 - val_accuracy: 0.8238 - lr: 6.5610e-04\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 44s 220ms/step - loss: 1.4038 - accuracy: 0.8104 - val_loss: 1.3330 - val_accuracy: 0.8383 - lr: 5.9049e-04\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 43s 217ms/step - loss: 1.2745 - accuracy: 0.8331 - val_loss: 1.2333 - val_accuracy: 0.8479 - lr: 5.3144e-04\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 43s 217ms/step - loss: 1.1877 - accuracy: 0.8480 - val_loss: 1.1826 - val_accuracy: 0.8512 - lr: 4.7830e-04\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 45s 223ms/step - loss: 1.1030 - accuracy: 0.8615 - val_loss: 1.1343 - val_accuracy: 0.8537 - lr: 4.3047e-04\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 45s 226ms/step - loss: 1.0503 - accuracy: 0.8690 - val_loss: 1.0741 - val_accuracy: 0.8673 - lr: 3.8742e-04\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 43s 214ms/step - loss: 0.9700 - accuracy: 0.8851 - val_loss: 1.0595 - val_accuracy: 0.8592 - lr: 3.4868e-04\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 0.9069 - accuracy: 0.8941 - val_loss: 1.0180 - val_accuracy: 0.8669 - lr: 3.1381e-04\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 0.8729 - accuracy: 0.8983 - val_loss: 0.9946 - val_accuracy: 0.8715 - lr: 2.8243e-04\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 0.8288 - accuracy: 0.9061 - val_loss: 0.9665 - val_accuracy: 0.8747 - lr: 2.5419e-04\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 41s 205ms/step - loss: 0.7774 - accuracy: 0.9182 - val_loss: 0.9290 - val_accuracy: 0.8802 - lr: 2.2877e-04\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 0.7418 - accuracy: 0.9255 - val_loss: 0.9148 - val_accuracy: 0.8792 - lr: 2.0589e-04\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 0.7187 - accuracy: 0.9267 - val_loss: 0.8911 - val_accuracy: 0.8847 - lr: 1.8530e-04\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 41s 205ms/step - loss: 0.6927 - accuracy: 0.9316 - val_loss: 0.8730 - val_accuracy: 0.8850 - lr: 1.6677e-04\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 41s 204ms/step - loss: 0.6749 - accuracy: 0.9333 - val_loss: 0.8630 - val_accuracy: 0.8843 - lr: 1.5009e-04\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 0.6461 - accuracy: 0.9410 - val_loss: 0.8397 - val_accuracy: 0.8892 - lr: 1.3509e-04\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 43s 217ms/step - loss: 0.6254 - accuracy: 0.9435 - val_loss: 0.8386 - val_accuracy: 0.8869 - lr: 1.2158e-04\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 42s 212ms/step - loss: 0.6119 - accuracy: 0.9445 - val_loss: 0.8259 - val_accuracy: 0.8850 - lr: 1.0942e-04\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 43s 217ms/step - loss: 0.5968 - accuracy: 0.9467 - val_loss: 0.8103 - val_accuracy: 0.8898 - lr: 9.8477e-05\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 44s 220ms/step - loss: 0.5718 - accuracy: 0.9552 - val_loss: 0.8013 - val_accuracy: 0.8940 - lr: 8.8629e-05\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 44s 218ms/step - loss: 0.5680 - accuracy: 0.9528 - val_loss: 0.7938 - val_accuracy: 0.8918 - lr: 7.9766e-05\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 44s 218ms/step - loss: 0.5554 - accuracy: 0.9577 - val_loss: 0.7931 - val_accuracy: 0.8882 - lr: 7.1790e-05\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.5446 - accuracy: 0.9575 - val_loss: 0.7769 - val_accuracy: 0.8918 - lr: 6.4611e-05\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 43s 218ms/step - loss: 0.5324 - accuracy: 0.9612 - val_loss: 0.7664 - val_accuracy: 0.8959 - lr: 5.8150e-05\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 43s 215ms/step - loss: 0.5228 - accuracy: 0.9618 - val_loss: 0.7688 - val_accuracy: 0.8911 - lr: 5.2335e-05\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.5214 - accuracy: 0.9622 - val_loss: 0.7643 - val_accuracy: 0.8937 - lr: 4.7101e-05\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 42s 211ms/step - loss: 0.5161 - accuracy: 0.9639 - val_loss: 0.7590 - val_accuracy: 0.8934 - lr: 4.2391e-05\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 42s 213ms/step - loss: 0.5113 - accuracy: 0.9628 - val_loss: 0.7509 - val_accuracy: 0.8976 - lr: 3.8152e-05\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 42s 212ms/step - loss: 0.4990 - accuracy: 0.9660 - val_loss: 0.7467 - val_accuracy: 0.8947 - lr: 3.4337e-05\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 43s 215ms/step - loss: 0.4958 - accuracy: 0.9662 - val_loss: 0.7496 - val_accuracy: 0.8930 - lr: 3.0903e-05\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.4921 - accuracy: 0.9664 - val_loss: 0.7358 - val_accuracy: 0.8976 - lr: 2.7813e-05\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 43s 214ms/step - loss: 0.4924 - accuracy: 0.9659 - val_loss: 0.7475 - val_accuracy: 0.8982 - lr: 2.5032e-05\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 43s 218ms/step - loss: 0.4832 - accuracy: 0.9687 - val_loss: 0.7396 - val_accuracy: 0.8979 - lr: 2.2528e-05\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.4814 - accuracy: 0.9676 - val_loss: 0.7381 - val_accuracy: 0.8953 - lr: 2.0276e-05\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 43s 215ms/step - loss: 0.4795 - accuracy: 0.9688 - val_loss: 0.7249 - val_accuracy: 0.8969 - lr: 1.8248e-05\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 43s 215ms/step - loss: 0.4825 - accuracy: 0.9656 - val_loss: 0.7307 - val_accuracy: 0.8995 - lr: 1.6423e-05\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 43s 214ms/step - loss: 0.4728 - accuracy: 0.9724 - val_loss: 0.7288 - val_accuracy: 0.8947 - lr: 1.4781e-05\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.4708 - accuracy: 0.9701 - val_loss: 0.7289 - val_accuracy: 0.8979 - lr: 1.3303e-05\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 43s 218ms/step - loss: 0.4750 - accuracy: 0.9688 - val_loss: 0.7268 - val_accuracy: 0.8969 - lr: 1.1973e-05\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.4681 - accuracy: 0.9709 - val_loss: 0.7238 - val_accuracy: 0.8998 - lr: 1.0775e-05\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 43s 215ms/step - loss: 0.4650 - accuracy: 0.9733 - val_loss: 0.7194 - val_accuracy: 0.8988 - lr: 9.6977e-06\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 43s 216ms/step - loss: 0.4625 - accuracy: 0.9704 - val_loss: 0.7248 - val_accuracy: 0.8959 - lr: 8.7280e-06\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 43s 215ms/step - loss: 0.4646 - accuracy: 0.9705 - val_loss: 0.7265 - val_accuracy: 0.8956 - lr: 7.8552e-06\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 42s 209ms/step - loss: 0.4604 - accuracy: 0.9728 - val_loss: 0.7191 - val_accuracy: 0.8992 - lr: 7.0697e-06\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 41s 207ms/step - loss: 0.4591 - accuracy: 0.9722 - val_loss: 0.7257 - val_accuracy: 0.8966 - lr: 6.3627e-06\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 42s 214ms/step - loss: 0.4627 - accuracy: 0.9714 - val_loss: 0.7239 - val_accuracy: 0.8969 - lr: 5.7264e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = create_model(pre_trained_model, total_class)\n",
    "model_history = fit_model(model, train_gen, test_gen, 50, [callbacks, lr_scheduler, early_stopping])\n",
    "\n",
    "save_model(model, 'EfficientNet_B0', 'Makanan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(train_path)\n",
    "\n",
    "wrong_pred, wrong_images, wrong_labels, wrong_actual_percentage, total_class_data = predict(model, test_gen, total_class)\n",
    "print('Accuracy: ', (test_gen.n - len(wrong_pred)) / test_gen.n * 100, '%')\n",
    "print('Wrong Prediction: ')\n",
    "for i in range(total_class):\n",
    "  print(class_names[i], ': ', wrong_actual_percentage[i], '/', total_class_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_missclassified_images(wrong_images, wrong_labels, wrong_pred, class_names, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(model, 'accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(model, 'loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
