{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image dataset from folder dataset/jajanan/test and dataset/jajanan/train using tf.data.Dataset also use num_parallel_calls to load image faster\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "# get path of dataset\n",
    "data_dir = pathlib.Path('dataset/jajanan')\n",
    "\n",
    "# get all image path\n",
    "image_path = list(data_dir.glob('*/*/*'))\n",
    "image_path = [str(path) for path in image_path]\n",
    "\n",
    "# get all label name\n",
    "label_name = sorted(item.name for item in data_dir.glob('train/*') if item.is_dir())\n",
    "\n",
    "# get all label index\n",
    "label_index = dict((name, index) for index, name in enumerate(label_name))\n",
    "\n",
    "# get all label\n",
    "image_label = [label_index[pathlib.Path(path).parent.name] for path in image_path]\n",
    "\n",
    "# create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_path, image_label))\n",
    "\n",
    "# load image\n",
    "def load_image(image_path, image_label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    return image, image_label\n",
    "\n",
    "# load image using parallel\n",
    "dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# shuffle dataset\n",
    "dataset = dataset.shuffle(1000)\n",
    "\n",
    "# split dataset 80% for train and 20% for test\n",
    "train_dataset = dataset.take(80)\n",
    "test_dataset = dataset.skip(80)\n",
    "\n",
    "# batch dataset\n",
    "train_dataset = train_dataset.batch(32)\n",
    "test_dataset = test_dataset.batch(32)\n",
    "\n",
    "# prefetch dataset\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "ResNet_V2_50 = 'https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5'\n",
    "Inception_V3 = 'https://tfhub.dev/google/imagenet/inception_v3/classification/5'\n",
    "MobileNet_V3_Large = 'https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5'\n",
    "Inception_ResNet_V2 = 'https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/5'\n",
    "NASNet_Large = 'https://tfhub.dev/google/imagenet/nasnet_large/classification/5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Kuliah\\Semester7\\Bangkit\\Capstone\\ml-model\\model_jajanan_2.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(e)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# model_ResNet = tf.keras.Sequential([\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#     hub.KerasLayer(ResNet_V2_50, trainable = False, input_shape = (224,224,3), name = 'Resnet_V2_50'),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#     tf.keras.layers.Flatten(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m#     tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# ])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m model_Inception_ResNet \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     hub\u001b[39m.\u001b[39;49mKerasLayer(Inception_ResNet_V2, trainable \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, input_shape \u001b[39m=\u001b[39;49m (\u001b[39m224\u001b[39;49m,\u001b[39m224\u001b[39;49m,\u001b[39m3\u001b[39;49m), name \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mInception_ResNet_V2\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m512\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, kernel_regularizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mregularizers\u001b[39m.\u001b[39ml2(\u001b[39m0.001\u001b[39m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.4\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m17\u001b[39m, activation \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m, name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mOutput_layer\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# model_NASNet = tf.keras.Sequential([\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m#     hub.KerasLayer(NASNet_Large, trainable = False, input_shape = (331,331,3), name = 'NASNet_Large'),\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m#     tf.keras.layers.Flatten(),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m#     tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Kuliah/Semester7/Bangkit/Capstone/ml-model/model_jajanan_2.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# ])\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:157\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[0;32m    154\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    156\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[0;32m    158\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[39m# Update with the defaults when using legacy TF1 Hub format.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:459\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    458\u001b[0m       set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\module_v2.py:120\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    117\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload_v2(\n\u001b[0;32m    118\u001b[0m       module_path, tags\u001b[39m=\u001b[39mtags, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_v2(module_path, tags\u001b[39m=\u001b[39;49mtags)\n\u001b[0;32m    121\u001b[0m obj\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m is_hub_module_v1  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:800\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(export_dir, os\u001b[39m.\u001b[39mPathLike):\n\u001b[0;32m    799\u001b[0m   export_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 800\u001b[0m result \u001b[39m=\u001b[39m load_partial(export_dir, \u001b[39mNone\u001b[39;49;00m, tags, options)[\u001b[39m\"\u001b[39m\u001b[39mroot\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    801\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:930\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39minit_scope():\n\u001b[0;32m    929\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 930\u001b[0m     loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    931\u001b[0m                     ckpt_options, options, filters)\n\u001b[0;32m    932\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    933\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:154\u001b[0m, in \u001b[0;36mLoader.__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proto \u001b[39m=\u001b[39m object_graph_proto\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_export_dir \u001b[39m=\u001b[39m export_dir\n\u001b[0;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_functions \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 154\u001b[0m     function_deserialization\u001b[39m.\u001b[39;49mload_function_def_library(\n\u001b[0;32m    155\u001b[0m         library\u001b[39m=\u001b[39;49mmeta_graph\u001b[39m.\u001b[39;49mgraph_def\u001b[39m.\u001b[39;49mlibrary,\n\u001b[0;32m    156\u001b[0m         saved_object_graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_proto,\n\u001b[0;32m    157\u001b[0m         wrapper_function\u001b[39m=\u001b[39;49m_WrapperFunction))\n\u001b[0;32m    158\u001b[0m \u001b[39m# Store a set of all concrete functions that have been set up with\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m# captures.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restored_concrete_functions \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:416\u001b[0m, in \u001b[0;36mload_function_def_library\u001b[1;34m(library, saved_object_graph, load_shared_name_suffix, wrapper_function)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39m# There is no need to copy all functions into the function def graph. It\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[39m# leads to a O(n^2) increase of memory when importing functions and the\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \u001b[39m# extra function definitions are a no-op since they already imported as a\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39m# function before and passed in explicitly (due to the topologic sort\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \u001b[39m# import).\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mas_default():\n\u001b[1;32m--> 416\u001b[0m   func_graph \u001b[39m=\u001b[39m function_def_lib\u001b[39m.\u001b[39;49mfunction_def_to_graph(\n\u001b[0;32m    417\u001b[0m       fdef,\n\u001b[0;32m    418\u001b[0m       structured_input_signature\u001b[39m=\u001b[39;49mstructured_input_signature,\n\u001b[0;32m    419\u001b[0m       structured_outputs\u001b[39m=\u001b[39;49mstructured_outputs)\n\u001b[0;32m    420\u001b[0m \u001b[39m# Restores gradients for function-call ops (not the same as ops that use\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m# custom gradients)\u001b[39;00m\n\u001b[0;32m    422\u001b[0m _restore_gradient_functions(func_graph, renamed_functions, loaded_gradients)\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\function_def_to_graph.py:87\u001b[0m, in \u001b[0;36mfunction_def_to_graph\u001b[1;34m(fdef, structured_input_signature, structured_outputs, input_shapes)\u001b[0m\n\u001b[0;32m     82\u001b[0m graph_def, nested_to_flat_tensor_name \u001b[39m=\u001b[39m function_def_to_graph_def(\n\u001b[0;32m     83\u001b[0m     fdef, input_shapes)\n\u001b[0;32m     85\u001b[0m \u001b[39mwith\u001b[39;00m func_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m     86\u001b[0m   \u001b[39m# Add all function nodes to the graph.\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m   importer\u001b[39m.\u001b[39;49mimport_graph_def_for_function(graph_def, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     89\u001b[0m   \u001b[39m# Initialize fields specific to FuncGraph.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[0;32m     91\u001b[0m   \u001b[39m# inputs\u001b[39;00m\n\u001b[0;32m     92\u001b[0m   input_tensor_names \u001b[39m=\u001b[39m [\n\u001b[0;32m     93\u001b[0m       nested_to_flat_tensor_name[arg\u001b[39m.\u001b[39mname] \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m fdef\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39minput_arg\n\u001b[0;32m     94\u001b[0m   ]\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py:414\u001b[0m, in \u001b[0;36mimport_graph_def_for_function\u001b[1;34m(graph_def, name)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimport_graph_def_for_function\u001b[39m(  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m    412\u001b[0m     graph_def, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    413\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Like import_graph_def but does not validate colocation constraints.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m   \u001b[39mreturn\u001b[39;00m _import_graph_def_internal(\n\u001b[0;32m    415\u001b[0m       graph_def, validate_colocation_constraints\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py:517\u001b[0m, in \u001b[0;36m_import_graph_def_internal\u001b[1;34m(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\u001b[0m\n\u001b[0;32m    505\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mstr\u001b[39m(e))\n\u001b[0;32m    507\u001b[0m   \u001b[39m# Create _DefinedFunctions for any imported functions.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m   \u001b[39m#\u001b[39;00m\n\u001b[0;32m    509\u001b[0m   \u001b[39m# We do this by creating _DefinedFunctions directly from `graph_def`, and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    514\u001b[0m   \u001b[39m# TODO(skyewm): fetch the TF_Functions directly from the TF_Graph\u001b[39;00m\n\u001b[0;32m    515\u001b[0m   \u001b[39m# TODO(skyewm): avoid sending serialized FunctionDefs back to the TF_Graph\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m   _ProcessNewOps(graph)\n\u001b[0;32m    519\u001b[0m \u001b[39mif\u001b[39;00m graph_def\u001b[39m.\u001b[39mlibrary \u001b[39mand\u001b[39;00m graph_def\u001b[39m.\u001b[39mlibrary\u001b[39m.\u001b[39mfunction:\n\u001b[0;32m    520\u001b[0m   functions \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfrom_library(graph_def\u001b[39m.\u001b[39mlibrary)\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py:248\u001b[0m, in \u001b[0;36m_ProcessNewOps\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m    245\u001b[0m colocation_pairs \u001b[39m=\u001b[39m {}\n\u001b[0;32m    247\u001b[0m \u001b[39mfor\u001b[39;00m new_op \u001b[39min\u001b[39;00m graph\u001b[39m.\u001b[39m_add_new_tf_operations(compute_devices\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   original_device \u001b[39m=\u001b[39m new_op\u001b[39m.\u001b[39;49mdevice\n\u001b[0;32m    249\u001b[0m   new_op\u001b[39m.\u001b[39m_set_device(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    250\u001b[0m   colocation_names \u001b[39m=\u001b[39m _GetColocationNames(new_op)\n",
      "File \u001b[1;32mc:\\Users\\airat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2265\u001b[0m, in \u001b[0;36mOperation.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2256\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m   2257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdevice\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2258\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"The name of the device to which this op has been assigned, if any.\u001b[39;00m\n\u001b[0;32m   2259\u001b[0m \n\u001b[0;32m   2260\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2263\u001b[0m \u001b[39m    device.\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2265\u001b[0m   \u001b[39mreturn\u001b[39;00m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationDevice(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use GPU\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "# use XLA to optimize performance\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# create model\n",
    "# model_ResNet = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(ResNet_V2_50, trainable = False, input_shape = (224,224,3), name = 'Resnet_V2_50'),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\n",
    "# ])\n",
    "\n",
    "# model_Inception = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(Inception_V3, trainable = False, input_shape = (224,224,3), name = 'Inception_V3'),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\n",
    "# ])\n",
    "\n",
    "# model_MobileNet = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(MobileNet_V3_Large, trainable = False, input_shape = (224,224,3), name = 'MobileNet_V3_Large'),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\n",
    "# ])\n",
    "\n",
    "model_Inception_ResNet = tf.keras.Sequential([\n",
    "    hub.KerasLayer(Inception_ResNet_V2, trainable = False, input_shape = (224,224,3), name = 'Inception_ResNet_V2'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\n",
    "])\n",
    "\n",
    "# model_NASNet = tf.keras.Sequential([\n",
    "#     hub.KerasLayer(NASNet_Large, trainable = False, input_shape = (331,331,3), name = 'NASNet_Large'),\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "#     tf.keras.layers.Dropout(0.4),\n",
    "#     tf.keras.layers.Dense(17, activation = 'softmax', name = 'Output_layer')\n",
    "# ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
